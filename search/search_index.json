{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Index \u00b6 This documentation discusses the paper Nader N. Nashed, Seif Eldawlatly and Gamal M Aly, \"A deep learning approach to single-trial classification for P300 spellers\", IEEE Middle East Conference on Biomedical Engineering, vol. 2018, no. 1, pp. 11-16, July 2018. Documentation Map \u00b6 Introduction Methodology Results References","title":"Index"},{"location":"#index","text":"This documentation discusses the paper Nader N. Nashed, Seif Eldawlatly and Gamal M Aly, \"A deep learning approach to single-trial classification for P300 spellers\", IEEE Middle East Conference on Biomedical Engineering, vol. 2018, no. 1, pp. 11-16, July 2018.","title":"Index"},{"location":"#documentation-map","text":"Introduction Methodology Results References","title":"Documentation Map"},{"location":"introduction/","text":"Introduction \u00b6 Goal of the paper The goal of the paper is to investigate the deep learning approach in achieving a higher accuracy while communicating the desired characters with the P300 speller from as little as a single trial. A Human Brain [15] Brain Computer Interface (BCI) is the interface made between a human's brain and a computer so that it's possible to get data directly from the brain into the computer or even further, the vice versa. Such technology could enable communication with individuals with severe motor disabilities, by communicating directly with the brain signals, for example, if a subject is want to control a robotic arm or even connected to a prosthetic arm, a signal could be taken directly from the brain to control this arm, or even if the subject is not able to talk, we could figure out what he want to say by directly communicating with the brain. This actually happens due to the fact that the brain functions by the communication between different neurons, those neurons send to each other messages in the form of voltage spikes, either high or low. Neuron Structure [16] Theoritcally, if we have access to each neuron's output we can record and regenerate the whole interactions needed for the brain to think about/plan and take an action. However, this task is not that simple taking into consideration a human brain has around 10^11 neurons, requiring 10^11 sensors . Thus, the 2 solutions we are left with are: Using the current knowledge we have about the human brain to narrow down to specific neurons to measure. Lowering the spatial resolution by using sensors. In general, this is not the only decision that needs to be taken to achieve the Brain Computer Interface, there are more information that we need to gather, and that could be managed by answering the following 4 questions: How to place the electrodes Which brain activity to consider Which computer program to use Which learning technique to use Next, we clarify the context that this paper is working on by answering those 4 questions. How To Place The Electrodes \u00b6 In the BCI field the sensors are called electrodes, and they read the voltage of a specific area, the smaller the number of neurons within this area the higher the spatial resolution of such method. Those electrodes are placed onto the individual's head. However, the more we need to increase the spatial resolution the further into the brain we need to place the electrodes, which implies we wouldn't be only putting the electrode on the subject's head, but we'd also need to be invasive and inject the electrode in the subject's head to be as close as possible to a specific neuron and reach the maximum spatial resolution. Luckily, with the current knowledge available about the brain, we can get meaningful information without a surgery, but of course with less spatial resolution. In summary, there are 3 ways to achieve such placement: non-invasive, semi-invasive and invasive, the following figure and table illustrate that further: Different BCI electrode placements [1] Method Non-Invasive Semi-Invasive Non-Invasive Recorded brain activity Electroencephalographic (EEG) Electrocorticography (ECoG) Individual neurons Electrode placement Over the head Over the brain Inside the brain Surgical operation Not required Required Required Spatial Resolution Least Medium High Hint Sometimes both semi-invasive and invasive are called invasive, as in any case they both require a surgery. Paper Approach This paper investigates the usage of EEG based activities. Which brain activity to consider \u00b6 There are many signals/activities that we could measure from the brain and consider for the BCI, Alpha, Beta, P300 ... etc. P300 activities on different subjects [18] This paper discusses the P300 brain activity which is elicited ~300 milliseconds after the presentation of an infrequent stimulus (for example, a visual stimulus or an auditory stimulus). This brain activity can be measured with electrodes placed on the parietal lobe of the brain. And it's usually used because of it's reproducibility and clarity in the BCI applications. Parietal lobe [19] It's also to be noted that, the p300 timing and voltage differs based on the subject age, the following figure shows how such difference occurs P300 activity over age [18] Which computer program to use \u00b6 Accordingly the program used for the interface is the P300 speller which works by showing the user a MxN matrix of the characters of interest (6x6 matrix for this paper) and flashing each row and column for K times (called K trials), for example if K is 1 (single trial) there will be 12 flashes (6 different row flashes and 6 different column flashes), K is 5 (5 trials) there will be 60 flashes (30 row flashes and 30 column flashes). Time diagram of a P300 speller [10] The flashes occur randomly and have Interintisification Intervals (ISI) of 100 ms between them. The user needs to focus on the character he wants to type each time, and once the screen flashes in front of him a brain activity shall evoke after 300 milliseconds which could be detected to figure out that the character the user is looking at is in the flashed row or column, 300 ms ago. Increasing the number of trials, would increase the detection accuracy, however each extra trial involves extra 12 flashes. Paper Approach This paper utilizes the reads P300 brain activitiy, and uses the P300 speller as the software for interaction. It also observes the effect of the deep learning approach on the decrease of the trials. Which Learning Technique To Use \u00b6 Sample EEG data [17] The data extracted from the brain is a voltage graph for each electrode, watching those graphs is like reading the 0's and 1's of different cores for a running operating system, what we can do though is to learn from those graphs, so that we could gather useful information from this high dimensionality data (considering each electrode a different dimension). Combining that with meaningful preprocessing filters we could reach great results. To learn from the brain activities both feature extraction and classification shall be utilized. There are multiple techniques for doing so. The classification problem in hand is considered a supervised learning one, as the classes are pre-known {P300 and non-P300} . Artificial Neural Network [14] Different approaches could be considered to learn the model, for example Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), Independent Componant Analysis (ICA), autoencoders, Fisher's Linear Discriminant Classifier, Maximum Likelihood Discriminant Classifier KNN, etc. Paper Approach This paper addresses the deep learning technique for the model, namely using stacked autoencoders with softmax a differentiable version of argmax , to learn the data compared to the usage of Principal Component Analysis (PCA) and Linear Discriminant Analysis (LDA) in previous models.","title":"Introduction"},{"location":"introduction/#introduction","text":"Goal of the paper The goal of the paper is to investigate the deep learning approach in achieving a higher accuracy while communicating the desired characters with the P300 speller from as little as a single trial. A Human Brain [15] Brain Computer Interface (BCI) is the interface made between a human's brain and a computer so that it's possible to get data directly from the brain into the computer or even further, the vice versa. Such technology could enable communication with individuals with severe motor disabilities, by communicating directly with the brain signals, for example, if a subject is want to control a robotic arm or even connected to a prosthetic arm, a signal could be taken directly from the brain to control this arm, or even if the subject is not able to talk, we could figure out what he want to say by directly communicating with the brain. This actually happens due to the fact that the brain functions by the communication between different neurons, those neurons send to each other messages in the form of voltage spikes, either high or low. Neuron Structure [16] Theoritcally, if we have access to each neuron's output we can record and regenerate the whole interactions needed for the brain to think about/plan and take an action. However, this task is not that simple taking into consideration a human brain has around 10^11 neurons, requiring 10^11 sensors . Thus, the 2 solutions we are left with are: Using the current knowledge we have about the human brain to narrow down to specific neurons to measure. Lowering the spatial resolution by using sensors. In general, this is not the only decision that needs to be taken to achieve the Brain Computer Interface, there are more information that we need to gather, and that could be managed by answering the following 4 questions: How to place the electrodes Which brain activity to consider Which computer program to use Which learning technique to use Next, we clarify the context that this paper is working on by answering those 4 questions.","title":"Introduction"},{"location":"introduction/#how-to-place-the-electrodes","text":"In the BCI field the sensors are called electrodes, and they read the voltage of a specific area, the smaller the number of neurons within this area the higher the spatial resolution of such method. Those electrodes are placed onto the individual's head. However, the more we need to increase the spatial resolution the further into the brain we need to place the electrodes, which implies we wouldn't be only putting the electrode on the subject's head, but we'd also need to be invasive and inject the electrode in the subject's head to be as close as possible to a specific neuron and reach the maximum spatial resolution. Luckily, with the current knowledge available about the brain, we can get meaningful information without a surgery, but of course with less spatial resolution. In summary, there are 3 ways to achieve such placement: non-invasive, semi-invasive and invasive, the following figure and table illustrate that further: Different BCI electrode placements [1] Method Non-Invasive Semi-Invasive Non-Invasive Recorded brain activity Electroencephalographic (EEG) Electrocorticography (ECoG) Individual neurons Electrode placement Over the head Over the brain Inside the brain Surgical operation Not required Required Required Spatial Resolution Least Medium High Hint Sometimes both semi-invasive and invasive are called invasive, as in any case they both require a surgery. Paper Approach This paper investigates the usage of EEG based activities.","title":"How To Place The Electrodes"},{"location":"introduction/#which-brain-activity-to-consider","text":"There are many signals/activities that we could measure from the brain and consider for the BCI, Alpha, Beta, P300 ... etc. P300 activities on different subjects [18] This paper discusses the P300 brain activity which is elicited ~300 milliseconds after the presentation of an infrequent stimulus (for example, a visual stimulus or an auditory stimulus). This brain activity can be measured with electrodes placed on the parietal lobe of the brain. And it's usually used because of it's reproducibility and clarity in the BCI applications. Parietal lobe [19] It's also to be noted that, the p300 timing and voltage differs based on the subject age, the following figure shows how such difference occurs P300 activity over age [18]","title":"Which brain activity to consider"},{"location":"introduction/#which-computer-program-to-use","text":"Accordingly the program used for the interface is the P300 speller which works by showing the user a MxN matrix of the characters of interest (6x6 matrix for this paper) and flashing each row and column for K times (called K trials), for example if K is 1 (single trial) there will be 12 flashes (6 different row flashes and 6 different column flashes), K is 5 (5 trials) there will be 60 flashes (30 row flashes and 30 column flashes). Time diagram of a P300 speller [10] The flashes occur randomly and have Interintisification Intervals (ISI) of 100 ms between them. The user needs to focus on the character he wants to type each time, and once the screen flashes in front of him a brain activity shall evoke after 300 milliseconds which could be detected to figure out that the character the user is looking at is in the flashed row or column, 300 ms ago. Increasing the number of trials, would increase the detection accuracy, however each extra trial involves extra 12 flashes. Paper Approach This paper utilizes the reads P300 brain activitiy, and uses the P300 speller as the software for interaction. It also observes the effect of the deep learning approach on the decrease of the trials.","title":"Which computer program to use"},{"location":"introduction/#which-learning-technique-to-use","text":"Sample EEG data [17] The data extracted from the brain is a voltage graph for each electrode, watching those graphs is like reading the 0's and 1's of different cores for a running operating system, what we can do though is to learn from those graphs, so that we could gather useful information from this high dimensionality data (considering each electrode a different dimension). Combining that with meaningful preprocessing filters we could reach great results. To learn from the brain activities both feature extraction and classification shall be utilized. There are multiple techniques for doing so. The classification problem in hand is considered a supervised learning one, as the classes are pre-known {P300 and non-P300} . Artificial Neural Network [14] Different approaches could be considered to learn the model, for example Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), Independent Componant Analysis (ICA), autoencoders, Fisher's Linear Discriminant Classifier, Maximum Likelihood Discriminant Classifier KNN, etc. Paper Approach This paper addresses the deep learning technique for the model, namely using stacked autoencoders with softmax a differentiable version of argmax , to learn the data compared to the usage of Principal Component Analysis (PCA) and Linear Discriminant Analysis (LDA) in previous models.","title":"Which Learning Technique To Use"},{"location":"methodology/","text":"Methodology \u00b6 The main phases followed in the paper are as following: Data Acquisition: collecting the data from the subject brain. Data Preprocessing: Preparing the data for processing by use of various filters. Feature Extraction: Getting specific features of the data to learn from. Classification: Learning whether the signal represent a P300 or not. Such phases are summarized in the following Diagram Methodology Block Diagram [13] For the feature extraction and the classification, the paper considers a different approach from a previous one that appeared in the paper A Principal Component Analysis Ensemble Classifier for P300 Speller Applications , which would be further clarified while discussing the used feature extraction and classification methods. Data Acquisition \u00b6 Emotiv EPOC headset [20] There are various headsets that could be used to capture the brain data, the EEG data for this paper is collected from an Emotiv EPOC which is installed based on the 10-20 international system, a system standardizing the names of different locations on the brain for electrode placement. The data is digitized and sampled at 240Hz . and bandpass filtered in the range of 0.4Hz to 45Hz , which means that only the data in this frequency range is considered. International 10-20 system [5] The collected data is taken from 2 healthy individuals, for each there was 36 captured characters as training data and 32 captured characters as test data. Each epoch (character) of the dataset included data from: 14 electrodes 12 intensifications of 100ms interval each (6 rows and 6 columns) repeated for 15 trials. Data Preprocessing \u00b6 Following are the data preprocessing filters applied, in order, over the data Common Average Reference \u00b6 The EEG reads data in range of microvolts, this voltage difference is taken against a ground electrode, which is connected to the headset's ground, and could pick up noise that does not reach other electrodes, to avoid such differences in voltage an online reference (for example, the common average of all electrodes) is picked up to be subtracted from all the electrodes, thus any noise that affects the electrodes gets removed equally from all the electrodes. Subtracting the common average of all the electrodes from each electrode is called Common Average Referencing. Moving Average Filter \u00b6 Moving average filter [22] A moving average filter is a simple low pass filter that smoothes the change of the data thus preventing been susceptable to outliers. The data in the paper goes through a moving average filter which is run over a 25-sample window. Z-Scores \u00b6 Finally, the Z-Scores of each recorded data is computed to normalize the data using the mean and standard deviation. Which allows for statistically equal treatment of the data dimensions. Feature Extraction \u00b6 After the data is preprocessed, we extract the features that we learn from The features in this paper were extracted from 4 electrodes, which are, based on the International 10-20 system located at: {O1, O2} : responsible for the visual processing {P7, P8} : responsible for the cognitive processing Later on, the outcome is compared to the learning from all of the 14 electrodes as found in the Results section Previous Approach for Feature Extraction \u00b6 In the previous paper approach the Principal Component Analysis (PCA) was used in reducing the dimensionality for the input data to extract the necessary features in an unsupervised manner. PCA \u00b6 Principle Component Analysis classifies by capturing the axes that maximizes the variance of the given data and it's used to capture maximum number of independent set of axes over which we could represent the data. PCA [23] Paper Approach for Feature Extraction \u00b6 In this paper autoencoders are used for feature extraction Autoencoders \u00b6 An autoencoder is a non-linear classifier which is powerful in capturing the minimum number of features required to classify the data. That occurs by creating bottleneck nodes that store only the needed data to regenerate the same input data. Autoencoders could be stacked, and in this paper 3 layers of stacked sparse autoencoders are used, which are later compared in the results.md . Stacked autoencoders [13] Using autoencoder allows use of non-linear transformation. over the linear transformation available through the PCA. We could also find in the results.md , multiple activation functions were investigated for this approach. Following are some properties of an autoencoder: Consists of hidden units Learns the hidden unit parameters by trying to reconstruct the input into the output neurons. Requires correct choice of number of features. Non-linear, which could make it easily overfitting in comparison with other linear techniques like the PCA. Which requires good selection of the input data and features. PCA vs autoencoder [3] Classification \u00b6 The problem in hand involves a supervised classification of the targets {P300, non P300}. Similar to the previous section, we describe next the previous approach and the current paper's approach. Previous Approach \u00b6 The supervised Linear Discriminant Analysis (LDA) was used in the previous approach. Linear Discriminant Analysis \u00b6 Linear Discriminant Analysis is a classifier that uses the data labels to classify by projecting the data on the directions of: Maximum variance between classes. Minimum variance within classes. LDA class distances [2] LDA's concept is very similar to the PCA except for the fact that they take the class targets into calculation. Paper Approach \u00b6 The used classifier for the paper's approach is a softmax regression classifier Softmax Classifier \u00b6 Represented by the formula \\[ f_{i}(\\vec{z})_{i}=\\displaystyle \\frac{e^{z_{i}}}{\\sum_{j=1}^{K}e^{z_{j}}} \\] The softmax regresion classifier is used for this approach. Which has the following properties: A generic version of logistic regression Number of outputs same as number of inputs Sum of the output neuron values is 1 Differential which eases backprobagation Unless similar output node values exist One of the outputs would be close to 1, the others would be almost 0 Softmax computation example [8]","title":"Methodology"},{"location":"methodology/#methodology","text":"The main phases followed in the paper are as following: Data Acquisition: collecting the data from the subject brain. Data Preprocessing: Preparing the data for processing by use of various filters. Feature Extraction: Getting specific features of the data to learn from. Classification: Learning whether the signal represent a P300 or not. Such phases are summarized in the following Diagram Methodology Block Diagram [13] For the feature extraction and the classification, the paper considers a different approach from a previous one that appeared in the paper A Principal Component Analysis Ensemble Classifier for P300 Speller Applications , which would be further clarified while discussing the used feature extraction and classification methods.","title":"Methodology"},{"location":"methodology/#data-acquisition","text":"Emotiv EPOC headset [20] There are various headsets that could be used to capture the brain data, the EEG data for this paper is collected from an Emotiv EPOC which is installed based on the 10-20 international system, a system standardizing the names of different locations on the brain for electrode placement. The data is digitized and sampled at 240Hz . and bandpass filtered in the range of 0.4Hz to 45Hz , which means that only the data in this frequency range is considered. International 10-20 system [5] The collected data is taken from 2 healthy individuals, for each there was 36 captured characters as training data and 32 captured characters as test data. Each epoch (character) of the dataset included data from: 14 electrodes 12 intensifications of 100ms interval each (6 rows and 6 columns) repeated for 15 trials.","title":"Data Acquisition"},{"location":"methodology/#data-preprocessing","text":"Following are the data preprocessing filters applied, in order, over the data","title":"Data Preprocessing"},{"location":"methodology/#common-average-reference","text":"The EEG reads data in range of microvolts, this voltage difference is taken against a ground electrode, which is connected to the headset's ground, and could pick up noise that does not reach other electrodes, to avoid such differences in voltage an online reference (for example, the common average of all electrodes) is picked up to be subtracted from all the electrodes, thus any noise that affects the electrodes gets removed equally from all the electrodes. Subtracting the common average of all the electrodes from each electrode is called Common Average Referencing.","title":"Common Average Reference"},{"location":"methodology/#moving-average-filter","text":"Moving average filter [22] A moving average filter is a simple low pass filter that smoothes the change of the data thus preventing been susceptable to outliers. The data in the paper goes through a moving average filter which is run over a 25-sample window.","title":"Moving Average Filter"},{"location":"methodology/#z-scores","text":"Finally, the Z-Scores of each recorded data is computed to normalize the data using the mean and standard deviation. Which allows for statistically equal treatment of the data dimensions.","title":"Z-Scores"},{"location":"methodology/#feature-extraction","text":"After the data is preprocessed, we extract the features that we learn from The features in this paper were extracted from 4 electrodes, which are, based on the International 10-20 system located at: {O1, O2} : responsible for the visual processing {P7, P8} : responsible for the cognitive processing Later on, the outcome is compared to the learning from all of the 14 electrodes as found in the Results section","title":"Feature Extraction"},{"location":"methodology/#previous-approach-for-feature-extraction","text":"In the previous paper approach the Principal Component Analysis (PCA) was used in reducing the dimensionality for the input data to extract the necessary features in an unsupervised manner.","title":"Previous Approach for Feature Extraction"},{"location":"methodology/#pca","text":"Principle Component Analysis classifies by capturing the axes that maximizes the variance of the given data and it's used to capture maximum number of independent set of axes over which we could represent the data. PCA [23]","title":"PCA"},{"location":"methodology/#paper-approach-for-feature-extraction","text":"In this paper autoencoders are used for feature extraction","title":"Paper Approach for Feature Extraction"},{"location":"methodology/#autoencoders","text":"An autoencoder is a non-linear classifier which is powerful in capturing the minimum number of features required to classify the data. That occurs by creating bottleneck nodes that store only the needed data to regenerate the same input data. Autoencoders could be stacked, and in this paper 3 layers of stacked sparse autoencoders are used, which are later compared in the results.md . Stacked autoencoders [13] Using autoencoder allows use of non-linear transformation. over the linear transformation available through the PCA. We could also find in the results.md , multiple activation functions were investigated for this approach. Following are some properties of an autoencoder: Consists of hidden units Learns the hidden unit parameters by trying to reconstruct the input into the output neurons. Requires correct choice of number of features. Non-linear, which could make it easily overfitting in comparison with other linear techniques like the PCA. Which requires good selection of the input data and features. PCA vs autoencoder [3]","title":"Autoencoders"},{"location":"methodology/#classification","text":"The problem in hand involves a supervised classification of the targets {P300, non P300}. Similar to the previous section, we describe next the previous approach and the current paper's approach.","title":"Classification"},{"location":"methodology/#previous-approach","text":"The supervised Linear Discriminant Analysis (LDA) was used in the previous approach.","title":"Previous Approach"},{"location":"methodology/#linear-discriminant-analysis","text":"Linear Discriminant Analysis is a classifier that uses the data labels to classify by projecting the data on the directions of: Maximum variance between classes. Minimum variance within classes. LDA class distances [2] LDA's concept is very similar to the PCA except for the fact that they take the class targets into calculation.","title":"Linear Discriminant Analysis"},{"location":"methodology/#paper-approach","text":"The used classifier for the paper's approach is a softmax regression classifier","title":"Paper Approach"},{"location":"methodology/#softmax-classifier","text":"Represented by the formula \\[ f_{i}(\\vec{z})_{i}=\\displaystyle \\frac{e^{z_{i}}}{\\sum_{j=1}^{K}e^{z_{j}}} \\] The softmax regresion classifier is used for this approach. Which has the following properties: A generic version of logistic regression Number of outputs same as number of inputs Sum of the output neuron values is 1 Differential which eases backprobagation Unless similar output node values exist One of the outputs would be close to 1, the others would be almost 0 Softmax computation example [8]","title":"Softmax Classifier"},{"location":"references/","text":"References \u00b6 Following are references either used in this documentation or include suplementary materials for this documentation and could aid in having broader understanding of different topics: [1]: bmseed: electrode types [2]: Rami Khushaba: PCA vs LDA [3]: Valerio Velardo: Autoencoders Explained Easily [4]: Interacoustics: P300 Evoked Potential: An Introduction Part 1 and Part 2 [5]: Wikipedia: 10-20 system (EEG) [6]: Stanford University - Andrew NG: Sparse Autoencoder [7]: CS231n Convolutional Neural Networks for Visual Recognition [8]: DeepAI: Softmax Classifier [9]: Stanford University: Sparse Autoencoder [10]: Research Gate: Stimulus and operating principle of P300-speller. When the subject counts the number of flashes of the character \"K\", P300 is elicited by the user's response. [11]: Wikipedia: Autoencoder [12]: Braingizer: A Brain-Controlled Wheelchair [13]: IEEE Middle East Conference on Biomedical Engineering: Nader N. Nashed, Seif Eldawlatly and Gamal M Aly: A deep learning approach to single-trial classification for P300 spellers [14]: Wikipedia: Artificial Neural Network [15]: nypost: Scientists use human neurons to grow 3-D brain tissues [16]: zuniv: physiology book [17]: research gate: Sample EEG dataset. Signals shows that the dataset is challenging due to different variations in the signals [18]: Wikipedia: P300 [19]: Wikipedia: Parietal lobe [20]: Emotiv EPOC [21]: Brain Products: Common Average Referencing [22]: Medium: Moving Average Filter [23]: Wikipedia: PCA","title":"References"},{"location":"references/#references","text":"Following are references either used in this documentation or include suplementary materials for this documentation and could aid in having broader understanding of different topics: [1]: bmseed: electrode types [2]: Rami Khushaba: PCA vs LDA [3]: Valerio Velardo: Autoencoders Explained Easily [4]: Interacoustics: P300 Evoked Potential: An Introduction Part 1 and Part 2 [5]: Wikipedia: 10-20 system (EEG) [6]: Stanford University - Andrew NG: Sparse Autoencoder [7]: CS231n Convolutional Neural Networks for Visual Recognition [8]: DeepAI: Softmax Classifier [9]: Stanford University: Sparse Autoencoder [10]: Research Gate: Stimulus and operating principle of P300-speller. When the subject counts the number of flashes of the character \"K\", P300 is elicited by the user's response. [11]: Wikipedia: Autoencoder [12]: Braingizer: A Brain-Controlled Wheelchair [13]: IEEE Middle East Conference on Biomedical Engineering: Nader N. Nashed, Seif Eldawlatly and Gamal M Aly: A deep learning approach to single-trial classification for P300 spellers [14]: Wikipedia: Artificial Neural Network [15]: nypost: Scientists use human neurons to grow 3-D brain tissues [16]: zuniv: physiology book [17]: research gate: Sample EEG dataset. Signals shows that the dataset is challenging due to different variations in the signals [18]: Wikipedia: P300 [19]: Wikipedia: Parietal lobe [20]: Emotiv EPOC [21]: Brain Products: Common Average Referencing [22]: Medium: Moving Average Filter [23]: Wikipedia: PCA","title":"References"},{"location":"results/","text":"Results \u00b6 The paper shows results for the following scenarios. Graphs for the different results could be found in the paper directly, only a description of the results are mentioned in this documentation. Single Trial Signal \u00b6 By varying the number of trials made per each character recognition, we change the difficulty of recognizing the P300 signal from non-P300 signal, thus reducing the 15 trials, to 5 trials and to 1 trial imposes a great challenge in correctly classifying the signal from a single trial. Number of Trials \u00b6 Comparing the paper's approach with the previous approach (PCA based) over the different trials the following results are found: For 15 trials: the current approach falls behind by ~2% For 5 trials: the current approach excels by ~5% For a single trial: the current approach excels by ~8% Number of channels in classification \u00b6 Through out the data acquisition phase only 4 selected channels were used, in this result section the results from 14 channels is compared to the 4 channels: The previous approach increased by ~7% when the 14 channels were used The current approach decreased by ~7% when the 14 channels were used In general, the average accuracy for the previous approach for the 14 channels are the same as the average accuracy for the current approach for the 4 channels only Activation Function \u00b6 As mentioned in the feature extraction section , multiple activation functions could be used, following are the results of using those functions: Linear activation exceled over the Logistic Sigmoid activation (by ~16% ) and over the Positive Saturating Linear function (by ~11% ) Linear activation resulted in ~54% accuracy Linear activation exceled over the Logistic Sigmoid activation (by ~16% ) Linear activation exceled over the Positive Saturating Linear function (by ~11% ) Hidden Layer Size of Stacked Autoencoders \u00b6 As mentioned in the feature extraction section , an autoencoder could have stacked hidden layers to reach the bottleneck, following are the results of varying the number of hidden layers: Gradually decreasing number of hidden layers had an accuracy of ~54% Gradually decreasing number of hidden layers after an initial increase had an accuracy of ~43% Constantly decreasing number of hidden layers had an accuracy of ~50% Constantly and aggressively decreasing number of hidden layers had an accuracy of ~45% Conclusion \u00b6 Results obtained from introducing a stacked autoencoder deep learning technique for P300 speller show a noticeable increase in classifying single trials over previous approach mentioned at the paper A Principal Component Analysis Ensemble Classifier for P300 Speller Applications . The work could be extended by usage of: Convolutional Neural Networks could be considered. Variational autoencoders and comparing its performance with the different stack size selections.","title":"Results"},{"location":"results/#results","text":"The paper shows results for the following scenarios. Graphs for the different results could be found in the paper directly, only a description of the results are mentioned in this documentation.","title":"Results"},{"location":"results/#single-trial-signal","text":"By varying the number of trials made per each character recognition, we change the difficulty of recognizing the P300 signal from non-P300 signal, thus reducing the 15 trials, to 5 trials and to 1 trial imposes a great challenge in correctly classifying the signal from a single trial.","title":"Single Trial Signal"},{"location":"results/#number-of-trials","text":"Comparing the paper's approach with the previous approach (PCA based) over the different trials the following results are found: For 15 trials: the current approach falls behind by ~2% For 5 trials: the current approach excels by ~5% For a single trial: the current approach excels by ~8%","title":"Number of Trials"},{"location":"results/#number-of-channels-in-classification","text":"Through out the data acquisition phase only 4 selected channels were used, in this result section the results from 14 channels is compared to the 4 channels: The previous approach increased by ~7% when the 14 channels were used The current approach decreased by ~7% when the 14 channels were used In general, the average accuracy for the previous approach for the 14 channels are the same as the average accuracy for the current approach for the 4 channels only","title":"Number of channels in classification"},{"location":"results/#activation-function","text":"As mentioned in the feature extraction section , multiple activation functions could be used, following are the results of using those functions: Linear activation exceled over the Logistic Sigmoid activation (by ~16% ) and over the Positive Saturating Linear function (by ~11% ) Linear activation resulted in ~54% accuracy Linear activation exceled over the Logistic Sigmoid activation (by ~16% ) Linear activation exceled over the Positive Saturating Linear function (by ~11% )","title":"Activation Function"},{"location":"results/#hidden-layer-size-of-stacked-autoencoders","text":"As mentioned in the feature extraction section , an autoencoder could have stacked hidden layers to reach the bottleneck, following are the results of varying the number of hidden layers: Gradually decreasing number of hidden layers had an accuracy of ~54% Gradually decreasing number of hidden layers after an initial increase had an accuracy of ~43% Constantly decreasing number of hidden layers had an accuracy of ~50% Constantly and aggressively decreasing number of hidden layers had an accuracy of ~45%","title":"Hidden Layer Size of Stacked Autoencoders"},{"location":"results/#conclusion","text":"Results obtained from introducing a stacked autoencoder deep learning technique for P300 speller show a noticeable increase in classifying single trials over previous approach mentioned at the paper A Principal Component Analysis Ensemble Classifier for P300 Speller Applications . The work could be extended by usage of: Convolutional Neural Networks could be considered. Variational autoencoders and comparing its performance with the different stack size selections.","title":"Conclusion"}]}